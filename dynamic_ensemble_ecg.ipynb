{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet, set_log_level\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7680, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"cleaned_ECG.csv\")\n",
    "df.drop(columns=['ECG2'],inplace=True) #considering only one ECG signal for forecasting\n",
    "df.columns = ['ds', 'y']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.015, 0.985]\n",
    "\n",
    "params = {\n",
    "    \"n_lags\": 24,\n",
    "    \"n_forecasts\": 7,\n",
    "    \"n_changepoints\": 20,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"ar_layers\": [32, 16, 16, 32],\n",
    "    \"epochs\": 70,\n",
    "    \"batch_size\": 64,\n",
    "    \"quantiles\": quantiles,\n",
    "}\n",
    "\n",
    "\n",
    "m = NeuralProphet(**params)\n",
    "m.set_plotting_backend(\"plotly-static\")\n",
    "set_log_level(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (7292, 2)\n",
      "Test shape: (412, 2)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = m.split_df(df, valid_p=0.05, local_split=True)\n",
    "print(f\"Train shape: {df_train.shape}\")\n",
    "print(f\"Test shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 75)                23100     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 76        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23176 (90.53 KB)\n",
      "Trainable params: 23176 (90.53 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "lstm_model = load_model(\"model_store/lstm_ecg.keras\")\n",
    "lstm_model.summary()\n",
    "\n",
    "with open(\"model_store/best_order_ecg.pkl\", \"rb\") as f:\n",
    "    loaded_order = pkl.load(f)\n",
    "\n",
    "with open(\"model_store/opt_no_states_ecg.pkl\", \"rb\") as f:\n",
    "    opt_states = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from utils import softmax_weighting, get_mae_errors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(np.array(df['y']).reshape(-1,1))\n",
    "\n",
    "def dynamic_ensemble_prediction(train, test):\n",
    "    train_hmm = train.reshape(-1,1)\n",
    "    train_hmm = scaler.transform(train_hmm)\n",
    "    test_hmm = test.reshape(-1,1)\n",
    "    test_hmm = scaler.transform(test_hmm)\n",
    "    hmm_history = train_hmm\n",
    "    history = np.array(train)\n",
    "\n",
    "    predictions = []\n",
    "    truth_values = []\n",
    "    lstm_preds = []\n",
    "    hmm_preds = []\n",
    "    arima_preds = []\n",
    "\n",
    "    for i in range(len(test)):\n",
    "        print(f'{i+1}/{len(test)}')\n",
    "        truth_values.append(test[i])\n",
    "        # LSTM\n",
    "        lstm_pred = lstm_model.predict(history[-24:].reshape(1,24))[0][0]\n",
    "        lstm_preds.append(lstm_pred)\n",
    "        # ARIMA\n",
    "        arima_model = ARIMA(history, order=loaded_order)\n",
    "        arima_fit = arima_model.fit()\n",
    "        arima_pred = arima_fit.forecast(steps=1)[0]\n",
    "        arima_preds.append(arima_pred)\n",
    "        # HMM\n",
    "        hmm_model = hmm.GaussianHMM(n_components=opt_states, covariance_type='diag', tol=0.0001, n_iter=100)\n",
    "        hmm_model.fit(hmm_history)\n",
    "        hidden_states = hmm_model.predict(hmm_history)\n",
    "        last_hidden_state = hidden_states[-1]\n",
    "        next_state_probs = hmm_model.transmat_[last_hidden_state]\n",
    "        predicted_state = np.argmax(next_state_probs)\n",
    "        predicted_value = hmm_model.means_[predicted_state][0]\n",
    "        hmm_pred = scaler.inverse_transform(np.array(predicted_value).reshape(-1,1))[0][0]\n",
    "        hmm_preds.append(hmm_pred)\n",
    "\n",
    "        #Error Measurement\n",
    "        arima_error = get_mae_errors(arima_preds, truth_values)\n",
    "        hmm_error = get_mae_errors(hmm_preds, truth_values)\n",
    "        lstm_error = get_mae_errors(lstm_preds, truth_values) \n",
    "\n",
    "        weights = softmax_weighting(arima_error, lstm_error, hmm_error) # Weighting algorithm\n",
    "\n",
    "        predictions.append(weights[0]*arima_pred + weights[1]*lstm_pred + weights[2]*hmm_pred)\n",
    "        history = np.append(history,test[i])\n",
    "        \n",
    "        if i != len(test)-1:\n",
    "            hmm_history = np.append(hmm_history,test_hmm[i]).reshape(-1,1)\n",
    "    \n",
    "    return predictions, arima_preds, hmm_preds, lstm_preds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/412\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "2/412\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "3/412\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "4/412\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "5/412\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "6/412\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "7/412\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "8/412\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "9/412\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "10/412\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "11/412\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "12/412\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "13/412\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "14/412\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "15/412\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "16/412\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "17/412\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "18/412\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "19/412\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "20/412\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "21/412\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "22/412\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "23/412\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "24/412\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "25/412\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "26/412\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "27/412\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "28/412\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "29/412\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "30/412\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "31/412\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "32/412\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "33/412\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "34/412\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "35/412\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "36/412\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "37/412\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "38/412\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "39/412\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "40/412\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "41/412\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "42/412\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "43/412\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "44/412\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "45/412\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "46/412\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "47/412\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "48/412\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "49/412\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "50/412\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "51/412\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "52/412\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "53/412\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "54/412\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "de_preds, arima_preds, hmm_preds, lstm_preds = dynamic_ensemble_prediction(np.array(df_train.y), np.array(df_test.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import math\n",
    "print('Dynamic Ensemble')\n",
    "print(f'R2 Score : {r2_score(df_test.y,de_preds)}')\n",
    "print(f'RMSE : {math.sqrt(mean_squared_error(df_test.y,de_preds))}')\n",
    "print(f'MAE : {mean_absolute_error(df_test.y,de_preds)}')\n",
    "print('ARIMA')\n",
    "print(f'R2 Score : {r2_score(df_test.y,arima_preds)}')\n",
    "print(f'RMSE : {math.sqrt(mean_squared_error(df_test.y,arima_preds))}')\n",
    "print(f'MAE : {mean_absolute_error(df_test.y,arima_preds)}')\n",
    "print('HMM')\n",
    "print(f'R2 Score : {r2_score(df_test.y,hmm_preds)}')\n",
    "print(f'RMSE : {math.sqrt(mean_squared_error(df_test.y,hmm_preds))}')\n",
    "print(f'MAE : {mean_absolute_error(df_test.y,hmm_preds)}')\n",
    "print('LSTM')\n",
    "print(f'R2 Score : {r2_score(df_test.y,lstm_preds)}')\n",
    "print(f'RMSE : {math.sqrt(mean_squared_error(df_test.y, lstm_preds))}')\n",
    "print(f'MAE : {mean_absolute_error(df_test.y,lstm_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.update_layout(title=\"Dynamic Ensemble with GOOG\")\n",
    "fig.add_trace(go.Scatter(x=df_test['ds'], y=df_test['y'], mode='lines', name='Real Data'))\n",
    "fig.add_trace(go.Scatter(x=df_test['ds'], y=de_preds, mode='lines', name='Proposed Method'))\n",
    "fig.add_trace(go.Scatter(x=df_test['ds'], y=arima_preds, mode='lines', name='ARIMA'))\n",
    "fig.add_trace(go.Scatter(x=df_test['ds'], y=hmm_preds, mode='lines', name='HMM'))\n",
    "fig.add_trace(go.Scatter(x=df_test['ds'], y=lstm_preds, mode='lines', name='LSTM'))\n",
    "fig.add_trace(go.Scatter(x=df_train['ds'], y=df_train['y'], mode='lines', name='Training'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
