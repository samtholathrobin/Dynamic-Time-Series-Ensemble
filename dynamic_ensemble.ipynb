{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOOGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet, set_log_level\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5138, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Google stocks.csv\")\n",
    "df.columns = ['ds', 'y']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (4792, 2)\n",
      "Test shape: (559, 2)\n"
     ]
    }
   ],
   "source": [
    "quantiles = [0.015, 0.985]\n",
    "\n",
    "params = {\n",
    "    \"n_lags\": 24,\n",
    "    \"n_forecasts\": 7,\n",
    "    \"n_changepoints\": 20,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"ar_layers\": [32, 16, 16, 32],\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 64,\n",
    "    \"quantiles\": quantiles,\n",
    "}\n",
    "\n",
    "\n",
    "m = NeuralProphet(**params)\n",
    "m.set_plotting_backend(\"plotly-static\")\n",
    "set_log_level(\"ERROR\")\n",
    "\n",
    "df_train, df_test = m.split_df(df, valid_p=0.1, local_split=True)\n",
    "print(f\"Train shape: {df_train.shape}\")\n",
    "print(f\"Test shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 75)                23100     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 76        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23176 (90.53 KB)\n",
      "Trainable params: 23176 (90.53 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "lstm_model = load_model(\"lstm_goog.keras\")\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4792, 2), (559, 2))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape,df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the Array: \n",
      "[100.20993805  98.81494904  98.45623779  97.73881531 100.37932587\n",
      "  97.73881531  95.80575562  98.9444809  102.04335022 101.85402679\n",
      " 101.87395477  99.21351624  98.3565979   97.69896698  97.94807434\n",
      "  99.35301208  96.83207703 100.41918182 101.0269928   99.93093872\n",
      " 100.17007446 101.11668396 102.60134888 104.55432129]\n",
      "Predict this y: \n",
      " [94.48052216]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "test_generator = TimeseriesGenerator(df.y.iloc[-583:].values,\n",
    "                                df.y.iloc[-583:].values,\n",
    "                                length=24,\n",
    "                                batch_size=1)\n",
    "\n",
    "X, y = test_generator[0]\n",
    "print(f'Given the Array: \\n{X.flatten()}')\n",
    "print(f'Predict this y: \\n {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559/559 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_preds = lstm_model.predict(test_generator).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best order: (2, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "with open(\"best_order_goog.pkl\", \"rb\") as f:\n",
    "    loaded_order = pkl.load(f)\n",
    "\n",
    "print(\"Loaded best order:\", loaded_order)\n",
    "def rolling_arima_predictions(train_data, test_data, order):\n",
    "    predictions = []\n",
    "    history = list(train_data)\n",
    "    for t in range(len(test_data)):\n",
    "        model = ARIMA(history, order=order)\n",
    "        model_fit = model.fit()\n",
    "        pred = model_fit.forecast(steps=1)[0]\n",
    "        predictions.append(pred)\n",
    "        history.append(test_data[t])\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_preds = rolling_arima_predictions(df_train['y'].values, df_test['y'].values, loaded_order) #9 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "\n",
    "with open(\"opt_no_states_goog.pkl\", \"rb\") as f:\n",
    "    opt_states = pkl.load(f)\n",
    "\n",
    "\n",
    "def rolling_hmm(original_dataset, original_test_dataset, opt_states, NUM_ITERS):\n",
    "    train_data = original_dataset[1:]-original_dataset[:original_dataset.shape[0]-1]\n",
    "    test_data = original_test_dataset[1:]-original_test_dataset[:original_test_dataset.shape[0]-1]\n",
    "    predictions = []\n",
    "    history = train_data\n",
    "    for t in range(len(test_data)):\n",
    "        model = hmm.GaussianHMM(n_components=opt_states, covariance_type='full', tol=0.0001, n_iter=NUM_ITERS)\n",
    "        model.fit(history)\n",
    "        hidden_states = model.predict(history)\n",
    "        last_hidden_state = hidden_states[-1]\n",
    "        next_state_probs = model.transmat_[last_hidden_state]\n",
    "        predicted_state = np.argmax(next_state_probs)\n",
    "        predicted_change = model.means_[predicted_state][0] # change prediction\n",
    "        pred = original_dataset[-2]+predicted_change # calculation of new price from previous price\n",
    "        predictions.append(pred)\n",
    "        history = np.append(history, test_data[t]).reshape(-1,1)\n",
    "        original_dataset = np.append(original_dataset, original_test_dataset[t])\n",
    "\n",
    "    model = hmm.GaussianHMM(n_components=opt_states, covariance_type='full', tol=0.0001, n_iter=NUM_ITERS)\n",
    "    model.fit(history)\n",
    "    hidden_states = model.predict(history)\n",
    "    last_hidden_state = hidden_states[-1]\n",
    "    next_state_probs = model.transmat_[last_hidden_state]\n",
    "    predicted_state = np.argmax(next_state_probs)\n",
    "    predicted_change = model.means_[predicted_state][0]\n",
    "    pred = original_dataset[-2]+predicted_change \n",
    "    predictions.append(pred)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4792, 1), (559, 1))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array = np.array(df_train['y']).reshape(-1,1)\n",
    "test_array = np.array(df_test['y']).reshape(-1,1)\n",
    "train_array.shape, test_array.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_preds = rolling_hmm(train_array, test_array, opt_states, 100)\n",
    "hmm_preds[0]= hmm_preds[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errors(df_test, out) -> np.float64:    \n",
    "    # Compares previous days predictions (max 10) to real values and returns mean_absolute_error\n",
    "    prev_days = 10\n",
    "    if len(out) < prev_days:\n",
    "        return (mean_absolute_error(df_test, out)) #returns error for situations where we only have readings less than prev_days\n",
    "    else:\n",
    "        return (mean_absolute_error(df_test[-prev_days:], out[-prev_days:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA error  = 2.2608443965641074\n",
      "HMM error = 3.0809604466142675\n",
      "LSTM error = 5.9743835449218805\n"
     ]
    }
   ],
   "source": [
    "hmm_error = get_errors(np.array(df_test.y), hmm_preds)\n",
    "arima_error = get_errors(np.array(df_test.y), arima_preds)\n",
    "lstm_error = get_errors(np.array(df_test.y), lstm_preds)\n",
    "\n",
    "print(f'ARIMA error  = {arima_error}')\n",
    "print(f'HMM error = {hmm_error}')\n",
    "print(f'LSTM error = {lstm_error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized inverse of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47343226, 0.17915768, 0.34741007])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalized_inverse_of_errors_weighting(model1, model2, model3):\n",
    "    errors = np.array([model1, model2, model3])\n",
    "    weights = (1 / errors) / np.sum(1 / errors)\n",
    "    return weights\n",
    "\n",
    "weights = normalized_inverse_of_errors_weighting(arima_error, lstm_error, hmm_error)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax or Exponential weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6827003 , 0.01665177, 0.30064793])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign weights exponentially based on the errors. This gives more emphasis to models with significantly lower errors.\n",
    "\n",
    "def softmax_weighting(model1, model2, model3):\n",
    "    errors = np.array([model1, model2, model3])\n",
    "    gamma = 1\n",
    "    weights = np.exp(-gamma * errors) / np.sum(np.exp(-gamma * errors))\n",
    "    return weights\n",
    "\n",
    "weights = softmax_weighting(arima_error, lstm_error, hmm_error)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error-Based Proportional Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59464225, 0.08515515, 0.32020261])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign weights proportional to the inverse of the squared errors (or another power of errors). \n",
    "# More aggressive in penalizing higher errors.\n",
    "\n",
    "def proportional_weighting(model1, model2, model3, k):\n",
    "    errors = np.array([model1, model2, model3])\n",
    "    weights = (1 / errors**k) / np.sum(1 / errors**k)\n",
    "    return weights\n",
    "\n",
    "weights = proportional_weighting(arima_error, lstm_error, hmm_error, 2)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank based Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54545455, 0.18181818, 0.27272727])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rank_based_weighting(model1, model2, model3):\n",
    "    errors = np.array([model1, model2, model3])\n",
    "    ranks = np.argsort(np.argsort(errors)) + 1\n",
    "    weights = (1 / ranks) / np.sum(1 / ranks)\n",
    "    return weights\n",
    "\n",
    "weights = rank_based_weighting(arima_error, lstm_error, hmm_error)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 95.09830475, 101.08678436, 100.91739655, 100.4690094 ,\n",
       "         99.51244354,  96.96160126,  94.80934143,  93.6136322 ,\n",
       "         92.73678589,  93.22502899,  95.50683594,  94.96876526,\n",
       "         90.87348175,  90.53469849,  88.83082581,  89.30910492,\n",
       "         89.92688751,  87.9440155 ,  89.48845673,  88.55182648,\n",
       "         87.61519623,  86.15045166,  88.63153839,  88.41233063]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df_train.y.iloc[-24:]).reshape(1,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.75459"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.predict(np.array(df_train.y.iloc[-24:]).reshape(1,24))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_ensemble_prediction(train, test):\n",
    "    history = np.array(train)\n",
    "    predictions = np.array([])\n",
    "    lstm_pred = lstm_model.predict(history[-24:].reshape(1,24))[0][0]\n",
    "    \n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
